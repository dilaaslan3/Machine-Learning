{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNB:\n",
    "    def __init__(self, prior=None, n_class=None, mean=None, variance=None, classes=None):\n",
    "        self.prior = prior\n",
    "        self.n_class = n_class\n",
    "        self.mean = mean\n",
    "        self.variance = variance\n",
    "        self.classes = classes\n",
    "\n",
    "    # get the mean and variance of the x values\n",
    "    def fit(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.mean = x.groupby(by=y).mean()\n",
    "        self.variance = x.groupby(by=y).var()\n",
    "        self.n_class = len(np.unique(y))\n",
    "        self.classes = np.unique(y)\n",
    "        self.prior = 1/self.n_class\n",
    "        return self\n",
    "\n",
    "    def mean_var(self):\n",
    "        m = np.array(self.mean)\n",
    "        v = np.array(self.variance)\n",
    "\n",
    "        self.mean_var = []\n",
    "        for i in range(len(m)):\n",
    "            m_row = m[i]\n",
    "            v_row = v[i]\n",
    "            for idx, value in enumerate(m_row):\n",
    "                mean = value\n",
    "                var = v_row[idx]\n",
    "                self.mean_var.append([mean, var])\n",
    "        mean_var_array = np.array(self.mean_var)\n",
    "        return mean_var_array\n",
    "\n",
    "    def split_by_class(self):\n",
    "        mean_var_array = self.mean_var()\n",
    "        summary_data_by_class = np.vsplit(mean_var_array, self.n_class)\n",
    "        return summary_data_by_class\n",
    "\n",
    "    # gaussian naive bayes probability equation\n",
    "    def gnb(self, x_value, x_mean, x_var):\n",
    "        \"\"\"\n",
    "        GNB = Gaussian naive bayes\n",
    "        x_value = x from test sample\n",
    "        x_mean = mean the feature by the class\n",
    "        x_var = variance the feature by the class\n",
    "        \"\"\"\n",
    "        self.x_value = x_value\n",
    "        self.x_mean = x_mean\n",
    "        self.x_var = x_var\n",
    "\n",
    "        # first part of the equation\n",
    "        eq_1 = 1/(np.sqrt(2 * np.pi * x_var))\n",
    "\n",
    "        # first part of the equation\n",
    "        # denominator\n",
    "        denominator = 2 * x_var\n",
    "\n",
    "        # numerator\n",
    "        numerator = (x_value - x_mean) ** 2\n",
    "\n",
    "        # exponent\n",
    "        expo = np.exp(-(numerator/denominator))\n",
    "\n",
    "        probability = eq_1 * expo\n",
    "\n",
    "        return probability\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        summary_data_by_class = self.split_by_class()\n",
    "        prob = []\n",
    "        for i in range(self.n_class):\n",
    "            class_k = summary_data_by_class[i]\n",
    "            for i in range(len(class_k)):\n",
    "                class_k_mean = class_k[i][0]\n",
    "                class_k_var = class_k[i][1]\n",
    "                x_value = x_test[i]\n",
    "                prob.append([self.gnb(x_value, class_k_mean, class_k_var)])\n",
    "\n",
    "        prob_array = np.array(prob)\n",
    "        prob_array_by_class = np.vsplit(prob_array, self.n_class)\n",
    "\n",
    "        final_probabilities = []\n",
    "        prob_of_class = []\n",
    "        \n",
    "        for i in prob_array_by_class:\n",
    "            final_probabilities.append(np.prod(i) * self.prior)\n",
    "        evidence = np.sum(final_probabilities)\n",
    "        \n",
    "        for i in range(len(final_probabilities)):\n",
    "            prob_of_class.append([final_probabilities[i]/evidence])\n",
    "        #print(final_probabilities)\n",
    "        print(prob_of_class)\n",
    "\n",
    "        maximum_prob = max(prob_of_class)\n",
    "        prob_index = prob_of_class.index(maximum_prob)\n",
    "        prediction = self.classes[prob_index]\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999999999998984], [1.0155078797792485e-13], [2.158248447741561e-20]]\n",
      "Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    iris_data = pd.read_csv(\"Iris.csv\")\n",
    "    X = iris_data[[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "    y = iris_data[\"Species\"].to_frame()\n",
    "    y = y.values.flatten()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    gnb = GNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    result = gnb.predict([5.7, 3.8, 1.7, 0.3])  # iris-setosa\n",
    "    # result = gnb.predict([6.1, 2.8, 4.7, 1.2])  # iris-versicolor\n",
    "    # result = gnb.predict([7.2, 3.6, 6.1, 2.5])  # iris-virginica\n",
    "    print(result)\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
